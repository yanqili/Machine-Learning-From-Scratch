{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">参考：\n",
    "\n",
    ">1、GBDT的python源码实现 \n",
    "\n",
    ">2、Machine-Learning-From-Scratch 1的作者的github \n",
    "\n",
    ">3、Machine Learning From Scratch 1的作者参考的github \n",
    "\n",
    ">4、Machine learning algorithms 1的作者参考的github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  >[1]: https://zhuanlan.zhihu.com/p/32181306\n",
    "  >[2]: https://github.com/RRdmlearning/Machine-Learning-From-Scratch\n",
    "  >[3]: https://github.com/eriklindernoren/ML-From-Scratch\n",
    "  >[4]: https://github.com/rushter/MLAlgorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 建立树节点类：二叉树节点，分割点、左右子节点、节点值\n",
    "\n",
    " - 建立决策树基类：因为不管回归树还是分类树，都是递归的建立树，根据一个标准找分割点，根据一个算法得到节点值\n",
    "\n",
    " - 建立分类树类：找分割点，用GINI系数或者熵；叶子节点，投票。和损失函数没有关系，可以做多分类，叶子节点的值是类别，不是数值\n",
    " \n",
    " - 建立回归树类：找分割点，分割前方差-（分割后左方差+分割后右方差），这个和损失函数选MSE时，相一致，这种分法，可以使loss降低。叶子节点的值，均值，也是和损失函数选MSE相一致，求导可知，均值可以使当前节点上样本loss最低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input X、y can be list or array, both ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decision_tree_model import ClassificationTree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0], [1, 1]])\n",
    "Y = np.array([0, 1])\n",
    "clf = ClassificationTree(max_depth=6)\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1]"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "clf.predict([[-1., 2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0:0? \n T->0\n F->1\n"
    }
   ],
   "source": [
    "clf.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "clf = ClassificationTree(max_depth=1)\n",
    "clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2:3.0? \n T->3:1.8? \n  T->2.0\n  F->1.0\n F->0.0\n"
    }
   ],
   "source": [
    "clf.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "clf.predict(iris.data[60:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "iris.target[60:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decision_tree_model import RegressionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[2.5]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X = [[0, 0], [2, 2]]\n",
    "y = [0.5, 2.5]\n",
    "clf = RegressionTree()\n",
    "clf.fit(X, y)\n",
    "clf.predict([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0:0? \n T->0.5\n F->2.5\n"
    }
   ],
   "source": [
    "clf.print_tree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.1 64-bit ('root': conda)",
   "language": "python",
   "name": "python36164bitrootconda03435e8a847c43f1836436f67ff0e288"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}